{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b30f49d8-de35-4d20-823a-3e84366fc68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "df66e1c7-a8c8-412c-9b44-bc9aa66efede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /root/miniconda3/lib/python3.9/site-packages (8.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/root/miniconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c10c0c1-ef0e-410b-a391-87156e30d9a4",
   "metadata": {},
   "source": [
    "## Image Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6cc3a159-5b82-4385-a66c-4b3df337cc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total lowquality images: 100\n",
      "total normal images: 1330\n"
     ]
    }
   ],
   "source": [
    "normal_image_path = 'ai_dataset/images/normal/'\n",
    "low_image_path = 'ai_dataset/images/low/'\n",
    "\n",
    "normal_img_list = os.listdir(normal_image_path) #디렉토리 내 모든 파일 불러오기\n",
    "normal_img_list_jpg = [img for img in normal_img_list if img.endswith(\".jpg\")] #지정된 확장자만 필터링\n",
    "\n",
    "low_img_list = os.listdir(low_image_path)\n",
    "low_img_list_jpg = [img for img in low_img_list if img.endswith(\".jpg\")]\n",
    "\n",
    "print('total lowquality images:', len(low_img_list_jpg))\n",
    "print('total normal images:', len(normal_img_list_jpg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "10da0f8e-a346-46d4-99a3-08c4727cfa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19315/2690945175.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  normal_images = np.array(normal_img_list_np)\n",
      "/tmp/ipykernel_19315/2690945175.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  lowquality_images = np.array(low_img_list_np)\n"
     ]
    }
   ],
   "source": [
    "normal_img_list_np = []\n",
    "low_img_list_np = []\n",
    "\n",
    "# normal image laoding (jpg to numpy)\n",
    "for i in normal_img_list_jpg:\n",
    "    img = Image.open(normal_image_path + i)\n",
    "    img_array = np.array(img)\n",
    "    normal_img_list_np.append(img_array)\n",
    "\n",
    "# lowquality image laoding (jpg to numpy)\n",
    "for i in low_img_list_jpg:\n",
    "    img = Image.open(low_image_path + i)\n",
    "    img_array = np.array(img)\n",
    "    low_img_list_np.append(img_array)\n",
    "\n",
    "#리스트를 numpy로 변환\n",
    "normal_images = np.array(normal_img_list_np)\n",
    "lowquality_images = np.array(low_img_list_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f5a888c4-c5a3-445c-9f11-95981521cc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1330 (1199, 1200, 3)\n",
      "100 (217, 82, 3)\n"
     ]
    }
   ],
   "source": [
    "print(len(normal_images), normal_images[0].shape)\n",
    "print(len(lowquality_images), lowquality_images[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f846245-40e0-4da7-865c-d28e5e811723",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Label Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "915f12d5-4571-4b9a-80c9-6dd76e5515b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total lowquality labels: 100\n",
      "total normal labels: 1330\n"
     ]
    }
   ],
   "source": [
    "normal_label_path = 'ai_dataset/labels/normal/'\n",
    "low_label_path = 'ai_dataset/labels/low/'\n",
    "\n",
    "normal_label_list = os.listdir(normal_label_path) #디렉토리 내 모든 파일 불러오기\n",
    "normal_label_list_txt = [txt for txt in normal_label_list if txt.endswith(\".txt\")] #지정된 확장자만 필터링\n",
    "\n",
    "low_label_list = os.listdir(low_label_path)\n",
    "low_label_list_txt = [txt for txt in low_label_list if txt.endswith(\".txt\")]\n",
    "\n",
    "print('total lowquality labels:', len(low_label_list_txt))\n",
    "print('total normal labels:', len(normal_label_list_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "04a07df7-9396-4ef7-9d99-0ca43ed42306",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_label_list_np = []\n",
    "low_label_list_np = []\n",
    "\n",
    "# normal label laoding (jpg to numpy)\n",
    "for i in normal_label_list_txt:\n",
    "    with open(normal_label_path + i, \"r\") as file:\n",
    "        label = file.readlines()    \n",
    "    label_array = np.array(label)\n",
    "    normal_label_list_np.append(label_array)\n",
    "\n",
    "# lowquality label laoding (jpg to numpy)\n",
    "for i in low_label_list_jpg:\n",
    "    with open(low_label_path + i, \"r\") as file:\n",
    "        label = file.readlines()    \n",
    "    label_array = np.array(label)\n",
    "    low_label_list_np.append(label_array)\n",
    "    \n",
    "    \n",
    "#리스트를 numpy로 변환\n",
    "normal_labels = np.array(normal_label_list_np)\n",
    "lowquality_labels = np.array(low_label_list_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4c3108d8-f2e8-4cf0-a21a-280df2a90bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1330, 1)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(normal_labels.shape)\n",
    "print(lowquality_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b843f021-8239-46ce-8aae-b0abce882bfe",
   "metadata": {},
   "source": [
    "## Annotation(Object) Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ed9225a5-1145-45c0-bcf9-794f306a27e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totla annotaion: 1330\n"
     ]
    }
   ],
   "source": [
    "annot_path = 'ai_dataset/normal_annot/'\n",
    "\n",
    "annot_list = os.listdir(annot_path) #디렉토리 내 모든 파일 불러오기\n",
    "annot_list_txt = [txt for txt in annot_list if txt.endswith(\".txt\")] #지정된 확장자만 필터링\n",
    "\n",
    "annot_list = os.listdir(annot_path)\n",
    "annot_list_txt = [txt for txt in annot_list if txt.endswith(\".txt\")]\n",
    "\n",
    "print('totla annotaion:', len(annot_list_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4577db88-5bcb-48a2-bd03-fc112206bc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.295 0.38125 0.193246 0.27955\n",
      "0 0.29375 0.39875 0.183865 0.791745\n"
     ]
    }
   ],
   "source": [
    "annot_list_np = []\n",
    "temp_list = []\n",
    "\n",
    "# normal annot laoding (txt to numpy)\n",
    "for i in annot_list_txt:\n",
    "    file = open(annot_path + i, \"r\")\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line:\n",
    "            break\n",
    "            \n",
    "        annot = line.strip()\n",
    "        annot_array = np.array(annot)\n",
    "        temp_list.append(annot_array)\n",
    "        if i == 'annot0001.txt':\n",
    "            print(annot)\n",
    "            \n",
    "    annot_list_np.append(temp_list)\n",
    "\n",
    "file.close()\n",
    "    \n",
    "#리스트를 numpy로 변환\n",
    "annotations = np.array(annot_list_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b7a2f833-7143-4108-8b8b-91de72f2cbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1330, 9209)\n"
     ]
    }
   ],
   "source": [
    "print(annotations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b108d-3603-458c-8f02-f2fff53f6020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#클래스 종류\n",
    "# 0 : Human\n",
    "# 4 : Safety Helmet\n",
    "# 5 : Safety Vest\n",
    "\n",
    "classes = ['Human', 'Safety Helmet', 'Safety Vest']\n",
    "\n",
    "idx = 10\n",
    "\n",
    "train_img = train_imgs[idx]\n",
    "c, x, y, h, w = train_labels[idx]\n",
    "print(c, x, y, h, w)\n",
    "x, w = x*320, w*320\n",
    "y, h = y*240, h*240\n",
    "train_labels = np.multiply(train_labels, [1, 320, 240, 240, 320])\n",
    "test_labels = np.multiply(test_labels, [1, 320, 240, 240, 320])\n",
    "\n",
    "rect = patches.Rectangle((x, y),\n",
    "                        w,\n",
    "                        h,\n",
    "                        linewidth = 2,\n",
    "                        edgecolor = 'r',\n",
    "                        facecolor = 'none')\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "plt.title(classes[int(c)])\n",
    "plt.imshow(train_img)\n",
    "ax.add_patch(rect)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5c7a1e-b1ab-4222-9c5a-4e376fa063f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = tf.keras.models. Sequential([\n",
    "    tf.keras.layers.Conv2D(filters = 32,\n",
    "                          kernel_size = (3,3),\n",
    "                          activation = 'relu',\n",
    "                          padding = 'SAME',\n",
    "                           input_shape = (240, 320, 3)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size = (2,2)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', padding = 'SAME'),\n",
    "    tf.keras.layers.MaxPool2D((2,2)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', padding = 'SAME'),\n",
    "    tf.keras.layers.MaxPool2D((2,2)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', padding = 'SAME'),\n",
    "    tf.keras.layers.MaxPool2D((2,2)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', padding = 'SAME'),\n",
    "    tf.keras.layers.MaxPool2D((2,2)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation = 'relu', padding = 'SAME'),\n",
    "    tf.keras.layers.GlobalAveragePooling2D()\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33dc966-e7cd-4f89-8e1c-607784cb1c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.keras.layers.Dense(256, activation = 'relu')(feature_extractor.output)\n",
    "classifier = tf.keras.layers.Dense(256, activation = 'relu')(classifier)\n",
    "classifier = tf.keras.layers.Dense(5, activation = 'softmax', name = 'cls')(classifier)\n",
    "\n",
    "bb_regressor = tf.keras.layers.Dense(256, activation = 'relu')(feature_extractor.output)\n",
    "bb_regressor = tf.keras.layers.Dense(256, activation = 'relu')(bb_regressor)\n",
    "bb_regressor = tf.keras.layers.Dense(4, name = 'bbox')(bb_regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d77b8-9fce-4e13-b3a0-0f571910ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detection = tf.keras.models.Model(inputs=feature_extractor.input, outputs=[classifier, bb_regressor])\n",
    "\n",
    "object_detection.compile(optimizer='adam',  \n",
    "                         loss={'cls':'sparse_categorical_crossentropy',\n",
    "                               'bbox':'mse'},\n",
    "                         loss_weights={'cls':1,\n",
    "                                       'bbox':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367c039f-1b8c-4033-9c21-f53a2912d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cls = train_labels[:,:1]\n",
    "train_bbox = train_labels[:,1:]\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(train_cls.shape)\n",
    "print(train_bbox.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76768483-23bc-49cc-a1f5-c53c9c7f0b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detection.fit(x = train_imgs,\n",
    "                    y = {'cls': train_cls, 'bbox': train_bbox},\n",
    "                    epochs = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6847eb5-17f3-4e7d-98df-96b67f0701ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 110\n",
    "\n",
    "c_label, x_label, y_label, h_label, w_label = train_labels[idx]\n",
    "\n",
    "rect_label = patches.Rectangle((x_label, y_label),\n",
    "                              w_label,\n",
    "                              h_label,\n",
    "                              linewidth = 2,\n",
    "                              edgecolor = 'r',\n",
    "                              facecolor = 'none')\n",
    "\n",
    "c_pred, bbox = object_detection.predict(train_imgs[[idx]])\n",
    "\n",
    "x, y, h, w = bbox[0]\n",
    "\n",
    "rect = patches.Rectangle((x, y),\n",
    "                        w,\n",
    "                        h,\n",
    "                        linewidth = 2,\n",
    "                        edgecolor = 'b',\n",
    "                        facecolor = 'none')\n",
    "\n",
    "print(classes[int(c_label)])\n",
    "print(classes[np.argmax(c_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715d5c3e-1e8c-4881-b270-a7c813e96b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "plt.imshow(train_imgs[idx])\n",
    "# ax.add_patch(rect_label)\n",
    "print(rect)\n",
    "ax.add_patch(rect)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
